# LOOM 开发路线图

## 概述
LOOM 是一个 LLM 原生的叙事运行时，专注于 AI Roleplay、互动小说、跑团式叙事和可长期运行的故事世界。采用非承载式架构，规则完全外置于 Markdown 文档，由 LLM 实时解释执行。

本路线图旨在将项目分解为逻辑上连贯的开发阶段，明确各阶段目标、时间线、依赖关系、里程碑、资源需求和风险缓解策略。

## 1. 开发阶段划分

### 阶段 1：基础运行时核心（Runtime Core）
**目标**：实现叙事失明的运行时核心，支持会话管理、回合调度、持久化。
**交付物**：
- 会话管理模块（创建、加载、保存、删除）
- 回合调度器（异步执行模型）
- 基础持久化（SQLite 存储会话状态）
- 崩溃恢复与安全边界
- 单元测试覆盖核心逻辑

### 阶段 2：规则层与解释层集成（Rule & Interpretation）
**目标**：实现 Markdown 规则加载和 LLM 解释，建立 BYOK LLM 接入。
**交付物**：
- Markdown 规则解析器（支持热加载）
- LLM 提供者抽象层（OpenAI、Anthropic、本地模型等）
- Prompt 组装引擎（动态注入规则、记忆、玩家输入）
- 解释层执行流水线（每回合调用 LLM 解释规则）
- 示例规则集（演示世界观、基调、冲突解决）

### 阶段 3：世界记忆层（World Memory）
**目标**：实现结构化记忆存储、检索和摘要生成。
**交付物**：
- 记忆数据结构（实体、事实、剧情线、地点等）
- 记忆存储与检索接口（SQLite + 向量索引可选）
- 记忆摘要生成器（LLM 驱动，生成上下文摘要）
- 记忆版本控制与回滚
- 记忆一致性检查工具

### 阶段 4：玩家干预层（Player Intervention）
**目标**：实现玩家输入处理和共创作机制。
**交付物**：
- 玩家输入解析器（支持 OOC 注释、世界编辑、Retcon）
- 干预意图识别与吸收机制
- 玩家权限边界管理（基于规则层）
- 实时干预反馈界面（CLI/Web）
- 干预历史与审计日志

### 阶段 5：系统集成与优化（Integration & Optimization）
**目标**：整合各层，优化性能，提供 CLI/Web 界面。
**交付物**：
- 完整端到端工作流（从规则加载到叙事生成）
- 性能优化（缓存、批处理、减少 LLM 调用成本）
- CLI 工具（创建会话、运行回合、查看状态）
- 基础 Web 界面（可选，用于可视化）
- 配置管理（环境变量、配置文件）

### 阶段 6：生态扩展（Ecosystem Expansion）
**目标**：构建工具链、模板、社区示例。
**交付物**：
- 规则模板库（多种叙事类型）
- 导入/导出工具（兼容其他叙事格式）
- 开发者文档与 API 参考
- 社区贡献指南
- 示例项目与演示视频

## 2. 时间线估计（以周为单位）

| 阶段 | 估计周数 | 累计周数 | 备注 |
|------|----------|----------|------|
| 阶段 1 | 3 周 | 3 周 | 基础运行时核心 |
| 阶段 2 | 4 周 | 7 周 | 规则与解释层集成 |
| 阶段 3 | 3 周 | 10 周 | 世界记忆层 |
| 阶段 4 | 3 周 | 13 周 | 玩家干预层 |
| 阶段 5 | 4 周 | 17 周 | 系统集成与优化 |
| 阶段 6 | 持续 | 17+ 周 | 生态扩展（并行进行） |

**总开发时间**：约 17 周（4 个月）达到可生产状态。

## 3. 依赖关系

- **阶段 1** 是后续所有阶段的基础。
- **阶段 2** 依赖于阶段 1 的会话管理和回合调度。
- **阶段 3** 依赖于阶段 2 的 LLM 接入（用于摘要生成）。
- **阶段 4** 依赖于阶段 2 的规则解释和阶段 3 的记忆。
- **阶段 5** 依赖于阶段 1-4 的完整功能。
- **阶段 6** 可在阶段 5 完成后并行开展。

**技术依赖顺序**：
1. 实现核心运行时（无 LLM）
2. 集成 LLM 提供者
3. 添加记忆存储
4. 添加玩家干预
5. 集成与优化
6. 生态建设

## 4. 里程碑定义

### 里程碑 1：核心运行时就绪
- **验收标准**：
  - 可以创建、保存、加载会话
  - 回合调度器能异步执行任务
  - 持久化存储会话状态
  - 通过单元测试（覆盖率 >80%）
- **交付物**：可运行的 Python 包 `loom-core`

### 里程碑 2：首个叙事生成
- **验收标准**：
  - 加载 Markdown 规则文件
  - 调用 LLM 生成符合规则的叙事段落
  - 玩家输入能影响叙事方向
  - 输出连贯且符合规则
- **交付物**：演示脚本，展示完整叙事循环

### 里程碑 3：记忆系统可用
- **验收标准**：
  - 记忆能存储和检索实体与事实
  - LLM 能生成上下文摘要
  - 记忆一致性检查工具工作
  - 支持记忆版本回滚
- **交付物**：记忆管理 CLI 工具

### 里程碑 4：玩家干预完整
- **验收标准**：
  - 支持 OOC 注释、世界编辑、Retcon
  - 干预意图被系统吸收并影响叙事
  - 权限边界根据规则层生效
  - 干预历史可审计
- **交付物**：玩家干预演示场景

### 里程碑 5：生产就绪
- **验收标准**：
  - 端到端工作流稳定
  - 性能满足实时交互需求（回合延迟 <5 秒）
  - CLI 工具完整
  - 有基础 Web 界面（可选）
  - 文档齐全
- **交付物**：发布版本 v1.0.0

### 里程碑 6：生态启动
- **验收标准**：
  - 提供至少 5 个规则模板
  - 有导入/导出工具
  - 社区贡献指南发布
  - 示例项目获得用户反馈
- **交付物**：模板库和社区网站

## 5. 资源需求

### 技术栈
- **编程语言**：Python 3.10+
- **异步框架**：asyncio
- **数据库**：SQLite（默认）、DuckDB（可选）、向量库（可选）
- **LLM 接入**：OpenAI API、Anthropic、本地模型（via LiteLLM）
- **Web 框架**：FastAPI（可选，用于 Web 界面）
- **前端**：HTML/JS（简单界面）或 Streamlit（快速原型）
- **版本控制**：Git

### 工具
- **开发环境**：VS Code、Poetry（依赖管理）、pytest（测试）
- **文档**：MkDocs、Swagger（API 文档）
- **CI/CD**：GitHub Actions
- **部署**：Docker、云服务器（可选）

### 外部依赖
- LLM API 密钥（BYOK）
- 开源库：sqlite3、aiohttp、pydantic、markdown-it
- 可选：向量数据库（Chroma、Qdrant）用于高级记忆检索

### 人力资源
- 1 名全栈开发者（Python、异步、LLM）
- 1 名叙事设计顾问（规则模板设计）
- 社区贡献者（生态扩展阶段）

## 6. 风险分析

### 技术风险
1. **LLM 解释不一致性**
   - **描述**：LLM 对同一规则可能产生不一致的解释，导致叙事断裂。
   - **缓解策略**：
     - 设计更精确的 Prompt 工程
     - 引入规则解释缓存
     - 提供解释后验证步骤（人工或自动）
2. **记忆膨胀与性能下降**
   - **描述**：长期运行后记忆数据量巨大，检索延迟增加。
   - **缓解策略**：
     - 实现记忆摘要和压缩
     - 分层存储（热/冷记忆）
     - 定期清理无关记忆
3. **规则冲突与歧义**
   - **描述**：Markdown 规则可能存在冲突，LLM 无法处理。
   - **缓解策略**：
     - 提供规则验证工具（静态分析）
     - 设计规则优先级机制
     - 允许运行时干预解决冲突
4. **LLM API 成本失控**
   - **描述**：频繁调用 LLM 导致高昂费用。
   - **缓解策略**：
     - 实现本地模型支持（Llama、Phi）
     - 缓存常见解释结果
     - 提供成本监控和预算告警

### 项目风险
1. **范围蔓延**
   - **缓解策略**：严格遵循非目标列表，定期评审需求。
2. **社区参与度低**
   - **缓解策略**：早期发布演示，吸引叙事爱好者，提供易用模板。
3. **技术债务积累**
   - **缓解策略**：每个阶段结束后进行代码重构，保持测试覆盖率。

## 7. 质量保证

### 测试策略
- **单元测试**：覆盖核心模块（运行时、规则解析、记忆存储）
- **集成测试**：验证各层协作（规则加载 → LLM 解释 → 记忆更新）
- **端到端测试**：模拟完整叙事会话，检查输出一致性
- **性能测试**：测量回合延迟、内存占用、LLM 调用次数
- **模糊测试**：对规则文件和玩家输入进行随机测试，确保鲁棒性

### 文档要求
- **架构文档**：描述五层模型、数据流、接口定义
- **用户指南**：如何编写规则、运行会话、使用干预功能
- **API 文档**：开发者接口（如提供自定义记忆存储）
- **示例与教程**：从零开始创建世界观
- **贡献指南**：代码规范、提交流程、测试要求

### 代码质量标准
- **代码风格**：遵循 Black、isort、flake8
- **类型注解**：全面使用 Type Hints，通过 mypy 检查
- **测试覆盖率**：核心模块 >90%，整体 >80%
- **代码审查**：所有合并请求需至少一人审查
- **持续集成**：自动运行测试、类型检查、代码风格检查

## 8. 核心理念符合性检查

- **非承载式架构**：框架不承载任何叙事规则 → 规则层完全独立，仅通过 Markdown 定义。
- **叙事失明**：运行时核心层对剧情内容保持无知 → 核心层仅管理会话、调度、持久化。
- **语言优先**：自然语言描述规则，LLM 解释软约束 → 规则层为 Markdown，解释层为 LLM。
- **持久性优先**：重视世界长期运行和记忆连续性 → 记忆层设计支持长期存储和摘要。

## 9. 下一步行动

1. 切换到 **🏗️ Design Emitter** 模式，细化各层技术设计。
2. 切换到 **💻 Code Executor** 模式，开始实现阶段 1。
3. 定期评审路线图，根据进展调整时间线。

---
*路线图版本：v1.0*
*最后更新：2025-12-30*
