"""
å¢å¼ºä¸Šä¸‹æ–‡æ„å»ºå™¨

å®ç°æ™ºèƒ½ä¸Šä¸‹æ–‡æ„å»ºï¼Œæ”¯æŒåŠ¨æ€ä¸Šä¸‹æ–‡æ„å»ºï¼ŒåŒ…æ‹¬å†å²å¯¹è¯ã€è®°å¿†ç‰‡æ®µã€è§„åˆ™çº¦æŸç­‰ã€‚
"""

import re
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Union

from ..memory.interfaces import MemoryEntity
from ..utils.logging_config import get_logger
from .reasoning_pipeline import ReasoningContext
from .rule_interpreter import InterpretationResult

logger = get_logger(__name__)


class ContextOptimizationStrategy(Enum):
    """ä¸Šä¸‹æ–‡ä¼˜åŒ–ç­–ç•¥"""

    BALANCED = "balanced"  # å¹³è¡¡ç­–ç•¥
    MEMORY_FOCUSED = "memory_focused"  # è®°å¿†é‡ç‚¹
    CONSTRAINT_FOCUSED = "constraint_focused"  # çº¦æŸé‡ç‚¹
    CONCISE = "concise"  # ç®€æ´ç­–ç•¥
    DETAILED = "detailed"  # è¯¦ç»†ç­–ç•¥


@dataclass
class ContextQualityMetrics:
    """ä¸Šä¸‹æ–‡è´¨é‡æŒ‡æ ‡"""

    total_tokens: int
    memory_coverage: float  # 0-1
    constraint_coverage: float  # 0-1
    relevance_score: float  # 0-1
    coherence_score: float  # 0-1
    optimization_level: float  # 0-1


class EnhancedContextBuilder:
    """å¢å¼ºä¸Šä¸‹æ–‡æ„å»ºå™¨"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–å¢å¼ºä¸Šä¸‹æ–‡æ„å»ºå™¨

        Args:
            config: é…ç½®å‚æ•°
        """
        self.config = config or {}
        self.template_registry = self._initialize_templates()
        self.optimization_strategies = self._initialize_strategies()

        logger.info(f"EnhancedContextBuilder initialized with config: {self.config}")

    async def build_optimized(
        self,
        context: ReasoningContext,
        interpretation: InterpretationResult,
        memories: List[Dict[str, Any]],
    ) -> str:
        """æ„å»ºä¼˜åŒ–æç¤º"""
        logger.info(f"Building optimized context for session {context.session_id}")

        # 1. é€‰æ‹©æœ€ç›¸å…³çš„è®°å¿†
        relevant_memories = await self._select_relevant_memories(
            context, memories, limit=self.config.get("max_memories", 5)
        )

        # 2. æå–å…³é”®çº¦æŸ
        key_constraints = self._extract_key_constraints(interpretation)

        # 3. é€‰æ‹©æœ€ä½³æ¨¡æ¿
        template = self._select_best_template(
            context, interpretation, relevant_memories
        )

        # 4. ç»„è£…æç¤º
        prompt = self._render_template(
            template,
            rules=context.rules_text,
            constraints=key_constraints,
            memories=relevant_memories,
            player_input=context.player_input,
            interventions=context.interventions,
            interpretation=interpretation,
        )

        # 5. ä¼˜åŒ–æç¤º
        optimized_prompt = await self._optimize_prompt(prompt, context)

        # 6. è¯„ä¼°è´¨é‡
        quality_metrics = self._evaluate_context_quality(
            optimized_prompt, context, interpretation, relevant_memories
        )

        logger.info(
            f"Context built: {len(optimized_prompt)} chars, "
            f"quality: {quality_metrics.relevance_score:.2f}"
        )

        return optimized_prompt

    async def build_with_strategy(
        self,
        context: ReasoningContext,
        interpretation: InterpretationResult,
        memories: List[Dict[str, Any]],
        strategy: ContextOptimizationStrategy,
    ) -> str:
        """ä½¿ç”¨æŒ‡å®šç­–ç•¥æ„å»ºä¸Šä¸‹æ–‡"""
        logger.info(f"Building context with strategy: {strategy.value}")

        # æ ¹æ®ç­–ç•¥è°ƒæ•´å‚æ•°
        strategy_config = self._get_strategy_config(strategy)

        # é€‰æ‹©è®°å¿†
        memory_limit = strategy_config.get("memory_limit", 5)
        relevant_memories = await self._select_relevant_memories(
            context,
            memories,
            limit=memory_limit,
            relevance_threshold=strategy_config.get("relevance_threshold", 0.3),
        )

        # æå–çº¦æŸ
        constraint_limit = strategy_config.get("constraint_limit", 10)
        key_constraints = self._extract_key_constraints(
            interpretation, limit=constraint_limit
        )

        # é€‰æ‹©æ¨¡æ¿
        template_type = strategy_config.get("template_type", "balanced")
        template = self._get_template_by_type(template_type)

        # æ¸²æŸ“
        prompt = self._render_template(
            template,
            rules=context.rules_text,
            constraints=key_constraints,
            memories=relevant_memories,
            player_input=context.player_input,
            interventions=context.interventions,
            interpretation=interpretation,
            strategy=strategy.value,
        )

        # ç­–ç•¥ç‰¹å®šä¼˜åŒ–
        optimized_prompt = await self._apply_strategy_optimization(
            prompt, strategy, context
        )

        return optimized_prompt

    async def _select_relevant_memories(
        self,
        context: ReasoningContext,
        memories: List[Dict[str, Any]],
        limit: int = 5,
        relevance_threshold: float = 0.3,
    ) -> List[Dict[str, Any]]:
        """é€‰æ‹©æœ€ç›¸å…³çš„è®°å¿†"""
        if not memories:
            return []

        # è®¡ç®—æ¯ä¸ªè®°å¿†çš„ç›¸å…³æ€§åˆ†æ•°
        scored_memories = []
        for memory in memories:
            score = self._calculate_memory_relevance(memory, context)
            if score >= relevance_threshold:
                scored_memories.append(
                    {
                        "memory": memory,
                        "score": score,
                        "type": memory.get("type", "unknown"),
                    }
                )

        # æŒ‰åˆ†æ•°æ’åº
        scored_memories.sort(key=lambda x: x["score"], reverse=True)

        # é€‰æ‹©å‰Nä¸ª
        selected = scored_memories[:limit]

        # ç¡®ä¿ç±»å‹å¤šæ ·æ€§
        diversified = self._diversify_memory_types(selected)

        logger.debug(
            f"Selected {len(diversified)} memories from {len(memories)} "
            f"(threshold: {relevance_threshold})"
        )

        return [item["memory"] for item in diversified]

    def _calculate_memory_relevance(
        self, memory: Dict[str, Any], context: ReasoningContext
    ) -> float:
        """è®¡ç®—è®°å¿†ç›¸å…³æ€§"""
        score = 0.0

        # åŸºäºè®°å¿†ç±»å‹çš„åŸºç¡€åˆ†æ•°
        mem_type = memory.get("type", "unknown")
        type_weights = {
            "fact": 0.3,
            "character": 0.4,
            "event": 0.5,
            "relationship": 0.4,
            "location": 0.3,
        }
        score += type_weights.get(mem_type, 0.2)

        # åŸºäºå†…å®¹åŒ¹é…
        memory_content = str(memory.get("content", "")).lower()
        player_input = context.player_input.lower()

        # å…³é”®è¯åŒ¹é…
        common_words = set(memory_content.split()) & set(player_input.split())
        if common_words:
            score += min(len(common_words) * 0.1, 0.3)

        # æ—¶é—´ç›¸å…³æ€§ï¼ˆå¦‚æœè®°å¿†æœ‰æ—¶é—´æˆ³ï¼‰
        memory_time = memory.get("timestamp")
        if memory_time and context.turn_number:
            # ç®€å•æ—¶é—´è¡°å‡ï¼šè¶Šè¿‘çš„è®°å¿†è¶Šç›¸å…³
            time_diff = context.turn_number - memory_time
            if isinstance(time_diff, (int, float)) and time_diff >= 0:
                decay = max(0.1, 1.0 - (time_diff * 0.1))
                score += decay * 0.2

        # ä¼šè¯ç›¸å…³æ€§
        session_id = memory.get("session_id")
        if session_id == context.session_id:
            score += 0.2

        return min(score, 1.0)

    def _diversify_memory_types(
        self, scored_memories: List[Dict[str, Any]], max_per_type: int = 2
    ) -> List[Dict[str, Any]]:
        """ç¡®ä¿è®°å¿†ç±»å‹å¤šæ ·æ€§"""
        if not scored_memories:
            return []

        # æŒ‰ç±»å‹åˆ†ç»„
        type_groups = {}
        for item in scored_memories:
            mem_type = item["type"]
            if mem_type not in type_groups:
                type_groups[mem_type] = []
            type_groups[mem_type].append(item)

        # ä»æ¯ä¸ªç±»å‹ä¸­é€‰æ‹©æœ€å¤šmax_per_typeä¸ª
        diversified = []
        for mem_type, items in type_groups.items():
            diversified.extend(items[:max_per_type])

        # é‡æ–°æŒ‰åˆ†æ•°æ’åº
        diversified.sort(key=lambda x: x["score"], reverse=True)

        return diversified

    def _extract_key_constraints(
        self, interpretation: InterpretationResult, limit: int = 10
    ) -> List[Any]:
        """æå–å…³é”®çº¦æŸ"""
        if not hasattr(interpretation, "constraints"):
            return []

        constraints = interpretation.constraints

        # æŒ‰é‡è¦æ€§æ’åº
        # 1. ç¦æ­¢æ€§è§„åˆ™ï¼ˆæœ€é‡è¦ï¼‰
        # 2. æƒé™æ€§è§„åˆ™
        # 3. å› æœå…³ç³»
        # 4. å…¶ä»–

        sorted_constraints = sorted(
            constraints,
            key=lambda c: (
                (
                    0
                    if getattr(c, "type", "") == "prohibition"
                    else (
                        1
                        if getattr(c, "type", "") == "permission"
                        else 2 if getattr(c, "type", "") == "causality" else 3
                    )
                ),
                -len(getattr(c, "content", "")),  # å†…å®¹è¶Šé•¿å¯èƒ½è¶Šé‡è¦
            ),
        )

        # æå–å…³é”®ä¿¡æ¯
        key_constraints = []
        for constraint in sorted_constraints[:limit]:
            constraint_type = getattr(constraint, "type", "unknown")
            constraint_content = getattr(constraint, "content", "")
            constraint_importance = getattr(constraint, "importance", "medium")

            key_constraints.append(
                {
                    "type": constraint_type,
                    "content": constraint_content,
                    "importance": constraint_importance,
                    "summary": self._summarize_constraint(constraint_content),
                }
            )

        return key_constraints

    def _summarize_constraint(self, constraint_content: str) -> str:
        """æ€»ç»“çº¦æŸ"""
        # ç®€åŒ–å®ç°ï¼šæå–å‰50ä¸ªå­—ç¬¦
        if len(constraint_content) <= 50:
            return constraint_content

        # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
        sentences = re.split(r"[ã€‚ï¼ï¼Ÿ]", constraint_content)
        if sentences and sentences[0]:
            return sentences[0][:50] + "..."

        return constraint_content[:50] + "..."

    def _select_best_template(
        self,
        context: ReasoningContext,
        interpretation: InterpretationResult,
        memories: List[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """é€‰æ‹©æœ€ä½³æ¨¡æ¿"""
        # æ ¹æ®ä¸Šä¸‹æ–‡ç‰¹å¾é€‰æ‹©æ¨¡æ¿
        context_features = self._analyze_context_features(
            context, interpretation, memories
        )

        # é€‰æ‹©æœ€åŒ¹é…çš„æ¨¡æ¿
        best_template = None
        best_score = 0.0

        for template_name, template in self.template_registry.items():
            score = self._calculate_template_match_score(template, context_features)
            if score > best_score:
                best_score = score
                best_template = template

        if not best_template:
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
            best_template = self.template_registry.get("balanced")

        logger.debug(f"Selected template with score: {best_score:.2f}")
        return best_template

    def _analyze_context_features(
        self,
        context: ReasoningContext,
        interpretation: InterpretationResult,
        memories: List[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡ç‰¹å¾"""
        features = {
            "memory_count": len(memories),
            "constraint_count": len(getattr(interpretation, "constraints", [])),
            "player_input_length": len(context.player_input),
            "rules_length": len(context.rules_text),
            "intervention_count": len(context.interventions),
            "turn_number": context.turn_number,
        }

        # è®¡ç®—å¤æ‚åº¦
        features["complexity"] = (
            features["memory_count"] * 0.2
            + features["constraint_count"] * 0.3
            + min(features["player_input_length"] / 100, 1.0) * 0.2
            + min(features["rules_length"] / 1000, 1.0) * 0.3
        )

        return features

    def _calculate_template_match_score(
        self, template: Dict[str, Any], context_features: Dict[str, Any]
    ) -> float:
        """è®¡ç®—æ¨¡æ¿åŒ¹é…åˆ†æ•°"""
        score = 0.0

        # åŸºäºå¤æ‚åº¦åŒ¹é…
        template_complexity = template.get("complexity", "medium")
        context_complexity = context_features.get("complexity", 0.5)

        if template_complexity == "low" and context_complexity < 0.3:
            score += 0.4
        elif template_complexity == "medium" and 0.3 <= context_complexity <= 0.7:
            score += 0.4
        elif template_complexity == "high" and context_complexity > 0.7:
            score += 0.4

        # åŸºäºè®°å¿†æ•°é‡åŒ¹é…
        memory_support = template.get("memory_support", "medium")
        memory_count = context_features.get("memory_count", 0)

        if memory_support == "low" and memory_count <= 2:
            score += 0.3
        elif memory_support == "medium" and 3 <= memory_count <= 6:
            score += 0.3
        elif memory_support == "high" and memory_count > 6:
            score += 0.3

        # åŸºäºçº¦æŸæ•°é‡åŒ¹é…
        constraint_support = template.get("constraint_support", "medium")
        constraint_count = context_features.get("constraint_count", 0)

        if constraint_support == "low" and constraint_count <= 3:
            score += 0.3
        elif constraint_support == "medium" and 4 <= constraint_count <= 8:
            score += 0.3
        elif constraint_support == "high" and constraint_count > 8:
            score += 0.3

        return score

    def _get_template_by_type(self, template_type: str) -> Dict[str, Any]:
        """æ ¹æ®ç±»å‹è·å–æ¨¡æ¿"""
        return self.template_registry.get(
            template_type, self.template_registry["balanced"]
        )

    def _render_template(
        self,
        template: Dict[str, Any],
        rules: str,
        constraints: List[Dict[str, Any]],
        memories: List[Dict[str, Any]],
        player_input: str,
        interventions: List[Dict[str, Any]],
        interpretation: InterpretationResult,
        **kwargs,
    ) -> str:
        """æ¸²æŸ“æ¨¡æ¿"""
        template_format = template.get("format", "default")

        if template_format == "detailed":
            return self._render_detailed_template(
                rules,
                constraints,
                memories,
                player_input,
                interventions,
                interpretation,
                **kwargs,
            )
        elif template_format == "concise":
            return self._render_concise_template(
                rules, constraints, memories, player_input, interventions, **kwargs
            )
        elif template_format == "memory_focused":
            return self._render_memory_focused_template(
                rules, constraints, memories, player_input, interventions, **kwargs
            )
        else:  # balanced/default
            return self._render_balanced_template(
                rules,
                constraints,
                memories,
                player_input,
                interventions,
                interpretation,
                **kwargs,
            )

    def _render_balanced_template(
        self,
        rules: str,
        constraints: List[Dict[str, Any]],
        memories: List[Dict[str, Any]],
        player_input: str,
        interventions: List[Dict[str, Any]],
        interpretation: InterpretationResult,
        **kwargs,
    ) -> str:
        """æ¸²æŸ“å¹³è¡¡æ¨¡æ¿"""
        strategy = kwargs.get("strategy", "balanced")

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå™äº‹å¼•æ“ï¼Œè´Ÿè´£æ ¹æ®ç»™å®šçš„ä¸–ç•Œè§‚è§„åˆ™å’Œä¸Šä¸‹æ–‡æ¨è¿›æ•…äº‹ã€‚

# ä¸–ç•Œè§‚è§„åˆ™
{rules}

# å…³é”®çº¦æŸï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
{self._format_constraints_for_prompt(constraints)}

# ç›¸å…³è®°å¿†ï¼ˆæŒ‰ç›¸å…³æ€§æ’åºï¼‰
{self._format_memories_for_prompt(memories)}

# ç©å®¶è¾“å…¥
{player_input}

# å¹²é¢„ä¿¡æ¯
{self._format_interventions_for_prompt(interventions)}

# æ¨ç†æŒ‡å¯¼
1. ä¸¥æ ¼éµå®ˆæ‰€æœ‰çº¦æŸæ¡ä»¶ï¼Œç‰¹åˆ«æ˜¯ç¦æ­¢æ€§è§„åˆ™
2. ä¿æŒä¸å†å²è®°å¿†çš„ä¸€è‡´æ€§
3. ç»´æŒå™äº‹åŸºè°ƒå’Œé£æ ¼
4. è‡ªç„¶åœ°æ¨è¿›æ•…äº‹å‘å±•
5. è€ƒè™‘è§’è‰²çš„åŠ¨æœºå’Œæ€§æ ¼
6. ç¡®ä¿é€»è¾‘å’Œå› æœå…³ç³»åˆç†

è¯·ç”Ÿæˆç¬¦åˆä»¥ä¸Šæ‰€æœ‰è¦æ±‚çš„å™äº‹å“åº”ã€‚ä¿æŒå“åº”é•¿åº¦é€‚ä¸­ï¼Œå†…å®¹ä¸°å¯Œä¸”æœ‰æ·±åº¦ã€‚"""

        return prompt

    def _render_detailed_template(
        self,
        rules: str,
        constraints: List[Dict[str, Any]],
        memories: List[Dict[str, Any]],
        player_input: str,
        interventions: List[Dict[str, Any]],
        interpretation: InterpretationResult,
        **kwargs,
    ) -> str:
        """æ¸²æŸ“è¯¦ç»†æ¨¡æ¿"""
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªé«˜çº§å™äº‹å¼•æ“ï¼Œéœ€è¦ç”Ÿæˆè¯¦ç»†ã€ä¸°å¯Œçš„å™äº‹å“åº”ã€‚

# è¯¦ç»†ä¸–ç•Œè§‚è§„åˆ™
{rules}

# æ·±åº¦è§„åˆ™åˆ†æ
{getattr(interpretation, 'narrative_output', 'æ— æ·±åº¦åˆ†æ')}

# å®Œæ•´çº¦æŸåˆ—è¡¨ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰
{self._format_constraints_detailed(constraints)}

# å®Œæ•´è®°å¿†ä¸Šä¸‹æ–‡
{self._format_memories_detailed(memories)}

# ç©å®¶è¾“å…¥åˆ†æ
ç©å®¶è¾“å…¥ï¼š{player_input}

è¾“å…¥åˆ†æï¼š{self._analyze_player_input(player_input)}

# å¹²é¢„å¤„ç†è¦æ±‚
{self._format_interventions_detailed(interventions)}

# è¯¦ç»†ç”Ÿæˆè¦æ±‚
1. ä¸¥æ ¼éµå®ˆæ‰€æœ‰çº¦æŸï¼Œç‰¹åˆ«æ˜¯æ ‡è®°ä¸º"é«˜é‡è¦æ€§"çš„çº¦æŸ
2. æ·±åº¦æ•´åˆå†å²è®°å¿†ï¼Œå¼•ç”¨å…·ä½“è®°å¿†å†…å®¹
3. ä¿æŒè§’è‰²æ€§æ ¼å’Œå…³ç³»çš„ä¸€è‡´æ€§
4. ç¡®ä¿æ—¶é—´çº¿å’Œäº‹ä»¶çš„é€»è¾‘è¿è´¯
5. ç»´æŒä¸–ç•Œè§‚è®¾å®šçš„åŸºè°ƒå’Œé£æ ¼
6. ç”Ÿæˆä¸°å¯Œã€è¯¦ç»†çš„å™äº‹ï¼ŒåŒ…å«ç¯å¢ƒæå†™ã€è§’è‰²äº’åŠ¨å’Œæƒ…èŠ‚æ¨è¿›
7. å“åº”é•¿åº¦åº”åœ¨300-800å­—ä¹‹é—´ï¼Œç¡®ä¿å†…å®¹å……å®

è¯·ç”Ÿæˆç¬¦åˆä»¥ä¸Šæ‰€æœ‰è¦æ±‚çš„è¯¦ç»†å™äº‹å“åº”ã€‚"""

        return prompt

    def _render_concise_template(
        self,
        rules: str,
        constraints: List[Dict[str, Any]],
        memories: List[Dict[str, Any]],
        player_input: str,
        interventions: List[Dict[str, Any]],
        **kwargs,
    ) -> str:
        """æ¸²æŸ“ç®€æ´æ¨¡æ¿"""
        # æ€»ç»“è§„åˆ™
        rules_summary = self._summarize_rules(rules, max_length=200)

        # åªä¿ç•™æœ€é‡è¦çš„çº¦æŸ
        key_constraints = constraints[:3] if constraints else []

        prompt = f"""å™äº‹å¼•æ“ï¼šæ ¹æ®è§„åˆ™å’Œè®°å¿†æ¨è¿›æ•…äº‹ã€‚

è§„åˆ™ï¼š{rules_summary}

å…³é”®çº¦æŸï¼š{self._format_constraints_concise(key_constraints)}

ç›¸å…³è®°å¿†ï¼š{self._format_memories_concise(memories[:2])}

ç©å®¶ï¼š{player_input}

å¹²é¢„ï¼š{self._format_interventions_concise(interventions)}

è¦æ±‚ï¼šéµå®ˆçº¦æŸï¼Œä¿æŒä¸€è‡´æ€§ï¼Œè‡ªç„¶æ¨è¿›ã€‚

å“åº”ï¼š"""

        return prompt

    def _render_memory_focused_template(
        self,
        rules: str,
        constraints: List[Dict[str, Any]],
        memories: List[Dict[str, Any]],
        player_input: str,
        interventions: List[Dict[str, Any]],
        **kwargs,
    ) -> str:
        """æ¸²æŸ“è®°å¿†é‡ç‚¹æ¨¡æ¿"""
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ³¨é‡å†å²è¿ç»­æ€§çš„å™äº‹å¼•æ“ã€‚

# ä¸–ç•Œè§‚è§„åˆ™ï¼ˆæ‘˜è¦ï¼‰
{self._summarize_rules(rules, max_length=300)}

# å¿…é¡»éµå®ˆçš„çº¦æŸ
{self._format_constraints_for_prompt(constraints[:5])}

# å†å²è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆè¿™æ˜¯é‡ç‚¹ï¼‰
{self._format_memories_as_context(memories)}

# å½“å‰æƒ…å†µ
ç©å®¶è¾“å…¥ï¼š{player_input}

å¹²é¢„ï¼š{self._format_interventions_for_prompt(interventions)}

# æ ¸å¿ƒè¦æ±‚
ä½ çš„å“åº”å¿…é¡»æ·±åº¦æ•´åˆä¸Šè¿°å†å²è®°å¿†ï¼Œä¿æŒä¸¥æ ¼çš„æ—¶é—´çº¿ã€è§’è‰²å‘å±•å’Œäº‹ä»¶è¿ç»­æ€§ã€‚å¼•ç”¨å…·ä½“è®°å¿†æ¥å¢å¼ºå™äº‹çš„çœŸå®æ„Ÿå’Œè¿è´¯æ€§ã€‚

ç”Ÿæˆä¸å†å²æ·±åº¦æ•´åˆçš„å™äº‹å“åº”ï¼š"""

        return prompt

    def _format_constraints_for_prompt(self, constraints: List[Dict[str, Any]]) -> str:
        """ä¸ºæç¤ºæ ¼å¼åŒ–çº¦æŸ"""
        if not constraints:
            return "ï¼ˆæ— æ˜ç¡®çº¦æŸï¼‰"

        formatted = []
        for i, constraint in enumerate(constraints):
            importance = constraint.get("importance", "medium")
            importance_marker = "âš ï¸" if importance == "high" else "â€¢"

            formatted.append(
                f"{importance_marker} [{constraint.get('type', 'constraint')}] "
                f"{constraint.get('summary', constraint.get('content', ''))}"
            )

        return "\n".join(formatted)

    def _format_constraints_detailed(self, constraints: List[Dict[str, Any]]) -> str:
        """è¯¦ç»†æ ¼å¼åŒ–çº¦æŸ"""
        if not constraints:
            return "æ— çº¦æŸæ¡ä»¶"

        formatted = []
        for i, constraint in enumerate(constraints):
            formatted.append(f"{i+1}. ç±»å‹ï¼š{constraint.get('type', 'unknown')}")
            formatted.append(f"   å†…å®¹ï¼š{constraint.get('content', '')}")
            formatted.append(f"   é‡è¦æ€§ï¼š{constraint.get('importance', 'medium')}")
            formatted.append("")

        return "\n".join(formatted)

    def _format_constraints_concise(self, constraints: List[Dict[str, Any]]) -> str:
        """ç®€æ´æ ¼å¼åŒ–çº¦æŸ"""
        if not constraints:
            return "æ— "

        return "ï¼Œ".join(
            [c.get("summary", c.get("content", ""))[:30] for c in constraints]
        )

    def _format_memories_for_prompt(self, memories: List[Dict[str, Any]]) -> str:
        """ä¸ºæç¤ºæ ¼å¼åŒ–è®°å¿†"""
        if not memories:
            return "ï¼ˆæ— ç›¸å…³è®°å¿†ï¼‰"

        formatted = []
        for i, memory in enumerate(memories):
            mem_type = memory.get("type", "unknown")
            content = memory.get("content", {})

            if isinstance(content, dict):
                summary = content.get("summary", str(content)[:80])
            else:
                summary = str(content)[:80]

            formatted.append(f"{i+1}. [{mem_type}] {summary}")

        return "\n".join(formatted)

    def _format_memories_detailed(self, memories: List[Dict[str, Any]]) -> str:
        """è¯¦ç»†æ ¼å¼åŒ–è®°å¿†"""
        if not memories:
            return "æ— ç›¸å…³è®°å¿†"

        formatted = []
        for i, memory in enumerate(memories):
            mem_type = memory.get("type", "unknown")
            content = memory.get("content", {})
            timestamp = memory.get("timestamp", "æœªçŸ¥æ—¶é—´")
            relevance = memory.get("relevance_score", 0.0)

            formatted.append(f"è®°å¿† #{i+1}:")
            formatted.append(f"  ç±»å‹ï¼š{mem_type}")
            formatted.append(f"  æ—¶é—´ï¼š{timestamp}")
            formatted.append(f"  ç›¸å…³æ€§ï¼š{relevance:.2f}")

            if isinstance(content, dict):
                for key, value in list(content.items())[:3]:
                    formatted.append(f"  {key}: {str(value)[:50]}")
            else:
                formatted.append(f"  å†…å®¹ï¼š{str(content)[:100]}")

            formatted.append("")

        return "\n".join(formatted)

    def _format_memories_concise(self, memories: List[Dict[str, Any]]) -> str:
        """ç®€æ´æ ¼å¼åŒ–è®°å¿†"""
        if not memories:
            return "æ— "

        summaries = []
        for memory in memories:
            content = memory.get("content", {})
            if isinstance(content, dict):
                summary = content.get("summary", "")
            else:
                summary = str(content)

            if summary:
                summaries.append(summary[:30])

        return "ï¼›".join(summaries[:2])

    def _format_memories_as_context(self, memories: List[Dict[str, Any]]) -> str:
        """å°†è®°å¿†æ ¼å¼åŒ–ä¸ºä¸Šä¸‹æ–‡"""
        if not memories:
            return "æ— å†å²è®°å¿†å¯ç”¨ã€‚"

        # æŒ‰ç±»å‹åˆ†ç»„
        type_groups = {}
        for memory in memories:
            mem_type = memory.get("type", "unknown")
            if mem_type not in type_groups:
                type_groups[mem_type] = []
            type_groups[mem_type].append(memory)

        formatted = []
        for mem_type, mem_list in type_groups.items():
            formatted.append(f"## {mem_type.capitalize()}è®°å¿†")
            for i, memory in enumerate(mem_list[:3]):  # æ¯ä¸ªç±»å‹æœ€å¤š3ä¸ª
                content = memory.get("content", {})
                if isinstance(content, dict):
                    summary = content.get("summary", str(content)[:60])
                else:
                    summary = str(content)[:60]

                formatted.append(f"{i+1}. {summary}")
            formatted.append("")

        return "\n".join(formatted)

    def _format_interventions_for_prompt(
        self, interventions: List[Dict[str, Any]]
    ) -> str:
        """ä¸ºæç¤ºæ ¼å¼åŒ–å¹²é¢„ä¿¡æ¯"""
        if not interventions:
            return "ï¼ˆæ— å¹²é¢„ï¼‰"

        formatted = []
        for interv in interventions:
            interv_type = interv.get("type", "unknown")
            content = interv.get("content", "")
            priority = interv.get("priority", "normal")

            priority_marker = (
                "ğŸ”´" if priority == "high" else "ğŸŸ¡" if priority == "medium" else "ğŸŸ¢"
            )
            formatted.append(f"{priority_marker} [{interv_type}] {content}")

        return "\n".join(formatted)

    def _format_interventions_detailed(
        self, interventions: List[Dict[str, Any]]
    ) -> str:
        """è¯¦ç»†æ ¼å¼åŒ–å¹²é¢„ä¿¡æ¯"""
        if not interventions:
            return "æ— å¹²é¢„ä¿¡æ¯"

        formatted = []
        for i, interv in enumerate(interventions):
            formatted.append(f"å¹²é¢„ #{i+1}:")
            formatted.append(f"  ç±»å‹ï¼š{interv.get('type', 'unknown')}")
            formatted.append(f"  å†…å®¹ï¼š{interv.get('content', '')}")
            formatted.append(f"  ä¼˜å…ˆçº§ï¼š{interv.get('priority', 'normal')}")
            formatted.append(f"  æ¥æºï¼š{interv.get('source', 'unknown')}")
            formatted.append("")

        return "\n".join(formatted)

    def _format_interventions_concise(self, interventions: List[Dict[str, Any]]) -> str:
        """ç®€æ´æ ¼å¼åŒ–å¹²é¢„ä¿¡æ¯"""
        if not interventions:
            return "æ— "

        types = [interv.get("type", "unknown") for interv in interventions]
        return f"{len(interventions)}ä¸ªå¹²é¢„ï¼ˆ{', '.join(types[:2])}ï¼‰"

    def _summarize_rules(self, rules: str, max_length: int = 200) -> str:
        """æ€»ç»“è§„åˆ™"""
        if len(rules) <= max_length:
            return rules

        # å°è¯•åœ¨æ®µè½è¾¹ç•Œæˆªæ–­
        paragraphs = rules.split("\n\n")
        summary = []
        total_length = 0

        for para in paragraphs:
            if total_length + len(para) + 2 <= max_length:
                summary.append(para)
                total_length += len(para) + 2
            else:
                # å½“å‰æ®µè½å¤ªé•¿ï¼Œæˆªæ–­
                remaining = max_length - total_length - 3  # ç•™å‡º"..."
                if remaining > 20:
                    summary.append(para[:remaining] + "...")
                break

        return "\n\n".join(summary)

    def _analyze_player_input(self, player_input: str) -> str:
        """åˆ†æç©å®¶è¾“å…¥"""
        if not player_input:
            return "æ— ç©å®¶è¾“å…¥"

        length = len(player_input)
        sentences = len(re.split(r"[ã€‚ï¼ï¼Ÿ]", player_input)) - 1

        analysis = []
        analysis.append(f"é•¿åº¦ï¼š{length}å­—ç¬¦")
        analysis.append(f"å¥å­æ•°ï¼š{sentences}")

        # ç®€å•æ„å›¾åˆ†æ
        if any(word in player_input for word in ["åšä»€ä¹ˆ", "æ€ä¹ˆåŠ", "å¦‚ä½•"]):
            analysis.append("æ„å›¾ï¼šå¯»æ±‚æŒ‡å¯¼/å»ºè®®")
        elif any(word in player_input for word in ["å»", "å‰å¾€", "è¿›å…¥"]):
            analysis.append("æ„å›¾ï¼šç§»åŠ¨/æ¢ç´¢")
        elif any(word in player_input for word in ["æ”»å‡»", "æˆ˜æ–—", "ä½¿ç”¨"]):
            analysis.append("æ„å›¾ï¼šæˆ˜æ–—/è¡ŒåŠ¨")
        elif any(word in player_input for word in ["è¯´", "å‘Šè¯‰", "é—®"]):
            analysis.append("æ„å›¾ï¼šå¯¹è¯/äº¤æµ")
        else:
            analysis.append("æ„å›¾ï¼šä¸€èˆ¬å™äº‹æ¨è¿›")

        return "ï¼›".join(analysis)

    async def _optimize_prompt(self, prompt: str, context: ReasoningContext) -> str:
        """ä¼˜åŒ–æç¤º"""
        # 1. ä»¤ç‰Œä¼˜åŒ–ï¼ˆç®€åŒ–å®ç°ï¼‰
        optimized = self._optimize_tokens(prompt)

        # 2. ç»“æ„ä¼˜åŒ–
        optimized = self._optimize_structure(optimized)

        # 3. æ¸…æ™°åº¦ä¼˜åŒ–
        optimized = self._optimize_clarity(optimized)

        return optimized

    def _optimize_tokens(self, prompt: str) -> str:
        """ä¼˜åŒ–ä»¤ç‰Œä½¿ç”¨"""
        # ç®€åŒ–å®ç°ï¼šç§»é™¤å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
        lines = prompt.split("\n")
        optimized_lines = []

        for line in lines:
            stripped = line.strip()
            if stripped:  # éç©ºè¡Œ
                # å‹ç¼©å¤šä¸ªç©ºæ ¼
                compressed = re.sub(r"\s+", " ", stripped)
                optimized_lines.append(compressed)

        return "\n".join(optimized_lines)

    def _optimize_structure(self, prompt: str) -> str:
        """ä¼˜åŒ–ç»“æ„"""
        # ç¡®ä¿æœ‰æ¸…æ™°çš„ç« èŠ‚åˆ†éš”
        sections = [
            "ä¸–ç•Œè§‚è§„åˆ™",
            "å…³é”®çº¦æŸ",
            "ç›¸å…³è®°å¿†",
            "ç©å®¶è¾“å…¥",
            "å¹²é¢„ä¿¡æ¯",
            "æ¨ç†æŒ‡å¯¼",
            "ç”Ÿæˆè¦æ±‚",
        ]

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸»è¦ç« èŠ‚
        for section in sections:
            if f"# {section}" not in prompt and f"## {section}" not in prompt:
                # æ²¡æœ‰æ˜ç¡®æ ‡è®°ï¼Œä½†å¯èƒ½åœ¨å…¶ä»–å½¢å¼ä¸­
                pass

        return prompt

    def _optimize_clarity(self, prompt: str) -> str:
        """ä¼˜åŒ–æ¸…æ™°åº¦"""
        # ç®€åŒ–å®ç°ï¼šç¡®ä¿æŒ‡ä»¤æ¸…æ™°
        clarity_improvements = [
            ("å¿…é¡»ä¸¥æ ¼éµå®ˆ", "å¿…é¡»ä¸¥æ ¼éµå®ˆ"),
            ("ç¡®ä¿", "ç¡®ä¿"),
            ("ä¿æŒ", "ä¿æŒ"),
        ]

        optimized = prompt
        for old, new in clarity_improvements:
            optimized = optimized.replace(old, new)

        return optimized

    async def _apply_strategy_optimization(
        self,
        prompt: str,
        strategy: ContextOptimizationStrategy,
        context: ReasoningContext,
    ) -> str:
        """åº”ç”¨ç­–ç•¥ç‰¹å®šä¼˜åŒ–"""
        if strategy == ContextOptimizationStrategy.CONCISE:
            return self._make_concise(prompt)
        elif strategy == ContextOptimizationStrategy.DETAILED:
            return self._add_detail(prompt, context)
        elif strategy == ContextOptimizationStrategy.MEMORY_FOCUSED:
            return self._emphasize_memories(prompt)
        elif strategy == ContextOptimizationStrategy.CONSTRAINT_FOCUSED:
            return self._emphasize_constraints(prompt)
        else:  # BALANCED
            return prompt

    def _make_concise(self, prompt: str) -> str:
        """ä½¿æç¤ºæ›´ç®€æ´"""
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        lines = [line for line in prompt.split("\n") if line.strip()]

        # åˆå¹¶çŸ­è¡Œ
        concise_lines = []
        buffer = ""

        for line in lines:
            if len(line) < 50 and not line.startswith("#") and not line.startswith("â€¢"):
                buffer += " " + line if buffer else line
            else:
                if buffer:
                    concise_lines.append(buffer)
                    buffer = ""
                concise_lines.append(line)

        if buffer:
            concise_lines.append(buffer)

        return "\n".join(concise_lines)

    def _add_detail(self, prompt: str, context: ReasoningContext) -> str:
        """æ·»åŠ ç»†èŠ‚"""
        # æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯
        detail_sections = []

        # æ·»åŠ ä¼šè¯ä¸Šä¸‹æ–‡
        detail_sections.append(f"# ä¼šè¯ä¸Šä¸‹æ–‡")
        detail_sections.append(f"ä¼šè¯IDï¼š{context.session_id}")
        detail_sections.append(f"å›åˆæ•°ï¼š{context.turn_number}")

        # æ·»åŠ ç”Ÿæˆå‚æ•°å»ºè®®
        detail_sections.append(f"# ç”Ÿæˆå‚æ•°å»ºè®®")
        detail_sections.append("å»ºè®®ä½¿ç”¨è¾ƒä½æ¸©åº¦ï¼ˆ0.6-0.8ï¼‰ä»¥ç¡®ä¿ä¸€è‡´æ€§")
        detail_sections.append("å»ºè®®ç”Ÿæˆé•¿åº¦ï¼š400-800å­—")

        # å°†æ–°éƒ¨åˆ†æ’å…¥åˆ°åˆé€‚ä½ç½®
        prompt_parts = prompt.split("\n\n")
        if len(prompt_parts) > 2:
            # åœ¨è§„åˆ™éƒ¨åˆ†åæ’å…¥
            prompt_parts.insert(2, "\n".join(detail_sections))

        return "\n\n".join(prompt_parts)

    def _emphasize_memories(self, prompt: str) -> str:
        """å¼ºè°ƒè®°å¿†éƒ¨åˆ†"""
        # åœ¨è®°å¿†éƒ¨åˆ†æ·»åŠ å¼ºè°ƒè¯´æ˜
        memory_section = "# ç›¸å…³è®°å¿†ï¼ˆé‡ç‚¹ï¼šå¿…é¡»æ·±åº¦æ•´åˆï¼‰"

        # æ›¿æ¢åŸæœ‰çš„è®°å¿†æ ‡é¢˜
        prompt = prompt.replace("# ç›¸å…³è®°å¿†", memory_section)
        prompt = prompt.replace("## ç›¸å…³è®°å¿†", memory_section)

        # æ·»åŠ è®°å¿†æ•´åˆè¯´æ˜
        integration_note = (
            "\n\n**è®°å¿†æ•´åˆè¦æ±‚**ï¼šä½ çš„å“åº”å¿…é¡»æ˜ç¡®å¼•ç”¨ä¸Šè¿°è®°å¿†ï¼Œå±•ç¤ºå†å²è¿ç»­æ€§ã€‚"
        )
        if "è¯·ç”Ÿæˆ" in prompt:
            # åœ¨ç”ŸæˆæŒ‡ä»¤å‰æ’å…¥
            parts = prompt.split("è¯·ç”Ÿæˆ")
            prompt = parts[0] + integration_note + "\n\nè¯·ç”Ÿæˆ" + parts[1]

        return prompt

    def _emphasize_constraints(self, prompt: str) -> str:
        """å¼ºè°ƒçº¦æŸéƒ¨åˆ†"""
        # åœ¨çº¦æŸéƒ¨åˆ†æ·»åŠ è­¦å‘Š
        constraint_section = "# å…³é”®çº¦æŸï¼ˆâš ï¸ å¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œè¿åå°†å¯¼è‡´å™äº‹ä¸ä¸€è‡´ï¼‰"

        # æ›¿æ¢åŸæœ‰çš„çº¦æŸæ ‡é¢˜
        prompt = prompt.replace("# å…³é”®çº¦æŸ", constraint_section)
        prompt = prompt.replace("## å…³é”®çº¦æŸ", constraint_section)

        # æ·»åŠ çº¦æŸæ£€æŸ¥è¯´æ˜
        check_note = "\n\n**çº¦æŸæ£€æŸ¥æ¸…å•**ï¼šç”Ÿæˆåè¯·è‡ªè¡Œæ£€æŸ¥æ˜¯å¦ï¼š1) éµå®ˆæ‰€æœ‰ç¦æ­¢æ€§è§„åˆ™ 2) ç¬¦åˆæ‰€æœ‰å› æœå…³ç³» 3) ä¸è¿åä»»ä½•æƒé™é™åˆ¶"
        if "è¯·ç”Ÿæˆ" in prompt:
            # åœ¨ç”ŸæˆæŒ‡ä»¤å‰æ’å…¥
            parts = prompt.split("è¯·ç”Ÿæˆ")
            prompt = parts[0] + check_note + "\n\nè¯·ç”Ÿæˆ" + parts[1]

        return prompt

    def _evaluate_context_quality(
        self,
        prompt: str,
        context: ReasoningContext,
        interpretation: InterpretationResult,
        memories: List[Dict[str, Any]],
    ) -> ContextQualityMetrics:
        """è¯„ä¼°ä¸Šä¸‹æ–‡è´¨é‡"""
        total_tokens = len(prompt) // 4  # è¿‘ä¼¼ä¼°è®¡

        # è®°å¿†è¦†ç›–ç‡
        memory_coverage = self._calculate_memory_coverage(prompt, memories)

        # çº¦æŸè¦†ç›–ç‡
        constraint_coverage = self._calculate_constraint_coverage(
            prompt, interpretation
        )

        # ç›¸å…³æ€§åˆ†æ•°
        relevance_score = self._calculate_relevance_score(prompt, context)

        # è¿è´¯æ€§åˆ†æ•°
        coherence_score = self._calculate_coherence_score(prompt)

        # ä¼˜åŒ–çº§åˆ«
        optimization_level = self._calculate_optimization_level(
            memory_coverage, constraint_coverage, relevance_score, coherence_score
        )

        return ContextQualityMetrics(
            total_tokens=total_tokens,
            memory_coverage=memory_coverage,
            constraint_coverage=constraint_coverage,
            relevance_score=relevance_score,
            coherence_score=coherence_score,
            optimization_level=optimization_level,
        )

    def _calculate_memory_coverage(
        self, prompt: str, memories: List[Dict[str, Any]]
    ) -> float:
        """è®¡ç®—è®°å¿†è¦†ç›–ç‡"""
        if not memories:
            return 0.0

        # æ£€æŸ¥æç¤ºä¸­æ˜¯å¦æåˆ°äº†è®°å¿†å†…å®¹
        coverage = 0.0

        for memory in memories:
            content = str(memory.get("content", ""))
            if content and len(content) > 10:
                # æ£€æŸ¥å…³é”®è¯æ˜¯å¦å‡ºç°åœ¨æç¤ºä¸­
                keywords = content.split()[:5]
                keyword_count = sum(1 for kw in keywords if kw in prompt)
                coverage += keyword_count / len(keywords) * 0.2

        return min(coverage, 1.0)

    def _calculate_constraint_coverage(
        self, prompt: str, interpretation: InterpretationResult
    ) -> float:
        """è®¡ç®—çº¦æŸè¦†ç›–ç‡"""
        if not hasattr(interpretation, "constraints") or not interpretation.constraints:
            return 0.0

        coverage = 0.0

        for constraint in interpretation.constraints[:5]:  # æ£€æŸ¥å‰5ä¸ªçº¦æŸ
            constraint_content = getattr(constraint, "content", "")
            if constraint_content and constraint_content in prompt:
                coverage += 0.2

        return min(coverage, 1.0)

    def _calculate_relevance_score(
        self, prompt: str, context: ReasoningContext
    ) -> float:
        """è®¡ç®—ç›¸å…³æ€§åˆ†æ•°"""
        score = 0.5  # åŸºç¡€åˆ†æ•°

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®éƒ¨åˆ†
        required_sections = ["ä¸–ç•Œè§‚è§„åˆ™", "ç©å®¶è¾“å…¥"]
        for section in required_sections:
            if section in prompt:
                score += 0.1

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context.session_id and str(context.session_id) in prompt:
            score += 0.1

        if str(context.turn_number) in prompt:
            score += 0.1

        return min(score, 1.0)

    def _calculate_coherence_score(self, prompt: str) -> float:
        """è®¡ç®—è¿è´¯æ€§åˆ†æ•°"""
        score = 0.5

        # æ£€æŸ¥ç»“æ„æ¸…æ™°åº¦
        lines = prompt.split("\n")
        section_headers = sum(
            1 for line in lines if line.startswith("#") and len(line.strip()) > 2
        )

        if section_headers >= 3:
            score += 0.2

        # æ£€æŸ¥æ®µè½é•¿åº¦
        paragraphs = prompt.split("\n\n")
        avg_paragraph_length = (
            sum(len(p) for p in paragraphs) / len(paragraphs) if paragraphs else 0
        )

        if 50 <= avg_paragraph_length <= 500:
            score += 0.2

        # æ£€æŸ¥æŒ‡ä»¤æ¸…æ™°åº¦
        if "å¿…é¡»" in prompt or "ç¡®ä¿" in prompt or "ä¿æŒ" in prompt:
            score += 0.1

        return min(score, 1.0)

    def _calculate_optimization_level(
        self,
        memory_coverage: float,
        constraint_coverage: float,
        relevance_score: float,
        coherence_score: float,
    ) -> float:
        """è®¡ç®—ä¼˜åŒ–çº§åˆ«"""
        weights = {"memory": 0.3, "constraint": 0.3, "relevance": 0.2, "coherence": 0.2}

        return (
            memory_coverage * weights["memory"]
            + constraint_coverage * weights["constraint"]
            + relevance_score * weights["relevance"]
            + coherence_score * weights["coherence"]
        )

    def _initialize_templates(self) -> Dict[str, Dict[str, Any]]:
        """åˆå§‹åŒ–æ¨¡æ¿"""
        return {
            "balanced": {
                "name": "å¹³è¡¡æ¨¡æ¿",
                "format": "balanced",
                "complexity": "medium",
                "memory_support": "medium",
                "constraint_support": "medium",
                "description": "å¹³è¡¡è€ƒè™‘è®°å¿†å’Œçº¦æŸçš„æ ‡å‡†æ¨¡æ¿",
            },
            "detailed": {
                "name": "è¯¦ç»†æ¨¡æ¿",
                "format": "detailed",
                "complexity": "high",
                "memory_support": "high",
                "constraint_support": "high",
                "description": "æä¾›è¯¦ç»†ä¸Šä¸‹æ–‡å’Œæ·±åº¦åˆ†æçš„æ¨¡æ¿",
            },
            "concise": {
                "name": "ç®€æ´æ¨¡æ¿",
                "format": "concise",
                "complexity": "low",
                "memory_support": "low",
                "constraint_support": "low",
                "description": "ç®€æ´é«˜æ•ˆçš„æ¨¡æ¿ï¼Œé€‚ç”¨äºç®€å•åœºæ™¯",
            },
            "memory_focused": {
                "name": "è®°å¿†é‡ç‚¹æ¨¡æ¿",
                "format": "memory_focused",
                "complexity": "medium",
                "memory_support": "high",
                "constraint_support": "medium",
                "description": "å¼ºè°ƒå†å²è®°å¿†å’Œè¿ç»­æ€§çš„æ¨¡æ¿",
            },
            "constraint_focused": {
                "name": "çº¦æŸé‡ç‚¹æ¨¡æ¿",
                "format": "balanced",  # ä½¿ç”¨å¹³è¡¡æ ¼å¼ä½†ä¼šç‰¹åˆ«å¼ºè°ƒçº¦æŸ
                "complexity": "medium",
                "memory_support": "medium",
                "constraint_support": "high",
                "description": "ç‰¹åˆ«å¼ºè°ƒè§„åˆ™çº¦æŸéµå®ˆçš„æ¨¡æ¿",
            },
        }

    def _initialize_strategies(
        self,
    ) -> Dict[ContextOptimizationStrategy, Dict[str, Any]]:
        """åˆå§‹åŒ–ç­–ç•¥"""
        return {
            ContextOptimizationStrategy.BALANCED: {
                "memory_limit": 5,
                "constraint_limit": 8,
                "relevance_threshold": 0.3,
                "template_type": "balanced",
                "description": "å¹³è¡¡ç­–ç•¥ï¼Œå…¼é¡¾è®°å¿†å’Œçº¦æŸ",
            },
            ContextOptimizationStrategy.MEMORY_FOCUSED: {
                "memory_limit": 8,
                "constraint_limit": 5,
                "relevance_threshold": 0.2,
                "template_type": "memory_focused",
                "description": "è®°å¿†é‡ç‚¹ç­–ç•¥ï¼Œå¼ºè°ƒå†å²è¿ç»­æ€§",
            },
            ContextOptimizationStrategy.CONSTRAINT_FOCUSED: {
                "memory_limit": 3,
                "constraint_limit": 10,
                "relevance_threshold": 0.4,
                "template_type": "constraint_focused",
                "description": "çº¦æŸé‡ç‚¹ç­–ç•¥ï¼Œç¡®ä¿è§„åˆ™éµå®ˆ",
            },
            ContextOptimizationStrategy.CONCISE: {
                "memory_limit": 2,
                "constraint_limit": 3,
                "relevance_threshold": 0.5,
                "template_type": "concise",
                "description": "ç®€æ´ç­–ç•¥ï¼Œç”Ÿæˆé«˜æ•ˆæç¤º",
            },
            ContextOptimizationStrategy.DETAILED: {
                "memory_limit": 6,
                "constraint_limit": 12,
                "relevance_threshold": 0.2,
                "template_type": "detailed",
                "description": "è¯¦ç»†ç­–ç•¥ï¼Œæä¾›æ·±åº¦ä¸Šä¸‹æ–‡",
            },
        }

    def _get_strategy_config(
        self, strategy: ContextOptimizationStrategy
    ) -> Dict[str, Any]:
        """è·å–ç­–ç•¥é…ç½®"""
        return self.optimization_strategies.get(
            strategy, self.optimization_strategies[ContextOptimizationStrategy.BALANCED]
        )

    # ========== æ‰¹é‡å¤„ç†å’Œé«˜çº§åŠŸèƒ½ ==========

    async def batch_build(
        self,
        contexts: List[ReasoningContext],
        interpretations: List[InterpretationResult],
        memories_list: List[List[Dict[str, Any]]],
    ) -> List[str]:
        """æ‰¹é‡æ„å»ºä¸Šä¸‹æ–‡"""
        if len(contexts) != len(interpretations) or len(contexts) != len(memories_list):
            raise ValueError("Input lists must have the same length")

        prompts = []
        for i, (context, interpretation, memories) in enumerate(
            zip(contexts, interpretations, memories_list)
        ):
            try:
                prompt = await self.build_optimized(context, interpretation, memories)
                prompts.append(prompt)
                logger.debug(f"Built context {i+1}/{len(contexts)}")
            except Exception as e:
                logger.error(f"Failed to build context {i+1}: {e}")
                # ä½¿ç”¨é™çº§æç¤º
                fallback_prompt = self._create_fallback_prompt(context)
                prompts.append(fallback_prompt)

        return prompts

    def _create_fallback_prompt(self, context: ReasoningContext) -> str:
        """åˆ›å»ºé™çº§æç¤º"""
        return f"""å™äº‹å¼•æ“ï¼šæ ¹æ®ä»¥ä¸‹ä¿¡æ¯æ¨è¿›æ•…äº‹ã€‚

è§„åˆ™ï¼š{context.rules_text[:200]}...

ç©å®¶è¾“å…¥ï¼š{context.player_input}

ç”Ÿæˆç¬¦åˆè§„åˆ™çš„å™äº‹å“åº”ã€‚"""

    def analyze_prompt_quality(self, prompt: str) -> Dict[str, Any]:
        """åˆ†ææç¤ºè´¨é‡"""
        lines = prompt.split("\n")
        paragraphs = prompt.split("\n\n")

        # åŸºæœ¬ç»Ÿè®¡
        stats = {
            "total_length": len(prompt),
            "line_count": len(lines),
            "paragraph_count": len(paragraphs),
            "section_count": sum(1 for line in lines if line.startswith("#")),
            "avg_line_length": (
                sum(len(line) for line in lines) / len(lines) if lines else 0
            ),
            "avg_paragraph_length": (
                sum(len(p) for p in paragraphs) / len(paragraphs) if paragraphs else 0
            ),
        }

        # å†…å®¹åˆ†æ
        content_analysis = {
            "has_rules": "ä¸–ç•Œè§‚è§„åˆ™" in prompt or "è§„åˆ™" in prompt,
            "has_constraints": "çº¦æŸ" in prompt or "å¿…é¡»" in prompt,
            "has_memories": "è®°å¿†" in prompt or "å†å²" in prompt,
            "has_instructions": "è¦æ±‚" in prompt or "æŒ‡å¯¼" in prompt,
            "has_player_input": "ç©å®¶è¾“å…¥" in prompt or "ç©å®¶" in prompt,
            "instruction_clarity": self._evaluate_instruction_clarity(prompt),
        }

        # è´¨é‡è¯„åˆ†
        quality_score = self._calculate_prompt_quality_score(stats, content_analysis)

        return {
            "statistics": stats,
            "content_analysis": content_analysis,
            "quality_score": quality_score,
            "quality_level": self._get_quality_level(quality_score),
            "suggestions": self._generate_quality_suggestions(stats, content_analysis),
        }

    def _evaluate_instruction_clarity(self, prompt: str) -> str:
        """è¯„ä¼°æŒ‡ä»¤æ¸…æ™°åº¦"""
        clarity_indicators = ["å¿…é¡»", "ç¡®ä¿", "ä¿æŒ", "è¦æ±‚", "ç¦æ­¢", "å…è®¸"]
        indicator_count = sum(
            1 for indicator in clarity_indicators if indicator in prompt
        )

        if indicator_count >= 4:
            return "high"
        elif indicator_count >= 2:
            return "medium"
        else:
            return "low"

    def _calculate_prompt_quality_score(
        self, stats: Dict[str, Any], content_analysis: Dict[str, Any]
    ) -> float:
        """è®¡ç®—æç¤ºè´¨é‡åˆ†æ•°"""
        score = 0.0

        # é•¿åº¦é€‚ä¸­ï¼ˆ500-3000å­—ç¬¦ï¼‰
        length = stats["total_length"]
        if 500 <= length <= 3000:
            score += 0.3
        elif 300 <= length < 500 or 3000 < length <= 5000:
            score += 0.2
        else:
            score += 0.1

        # ç»“æ„è‰¯å¥½ï¼ˆæœ‰ç« èŠ‚ï¼‰
        if stats["section_count"] >= 3:
            score += 0.2

        # å†…å®¹å®Œæ•´
        required_elements = ["has_rules", "has_player_input"]
        element_count = sum(
            1 for elem in required_elements if content_analysis.get(elem, False)
        )
        score += (element_count / len(required_elements)) * 0.3

        # æŒ‡ä»¤æ¸…æ™°
        if content_analysis["instruction_clarity"] == "high":
            score += 0.2
        elif content_analysis["instruction_clarity"] == "medium":
            score += 0.1

        return min(score, 1.0)

    def _get_quality_level(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 0.8:
            return "ä¼˜ç§€"
        elif score >= 0.6:
            return "è‰¯å¥½"
        elif score >= 0.4:
            return "ä¸€èˆ¬"
        else:
            return "è¾ƒå·®"

    def _generate_quality_suggestions(
        self, stats: Dict[str, Any], content_analysis: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆè´¨é‡æ”¹è¿›å»ºè®®"""
        suggestions = []

        # é•¿åº¦å»ºè®®
        length = stats["total_length"]
        if length < 300:
            suggestions.append("æç¤ºå¯èƒ½è¿‡çŸ­ï¼Œè€ƒè™‘æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡")
        elif length > 5000:
            suggestions.append("æç¤ºå¯èƒ½è¿‡é•¿ï¼Œè€ƒè™‘ç²¾ç®€å†…å®¹")

        # ç»“æ„å»ºè®®
        if stats["section_count"] < 2:
            suggestions.append("æ·»åŠ æ›´å¤šç« èŠ‚æ ‡é¢˜ä»¥æ”¹å–„ç»“æ„")

        # å†…å®¹å»ºè®®
        if not content_analysis["has_rules"]:
            suggestions.append("æ·»åŠ ä¸–ç•Œè§‚è§„åˆ™éƒ¨åˆ†")

        if not content_analysis["has_player_input"]:
            suggestions.append("æ˜ç¡®æ ‡è¯†ç©å®¶è¾“å…¥")

        if content_analysis["instruction_clarity"] == "low":
            suggestions.append("æ·»åŠ æ›´æ˜ç¡®çš„æŒ‡ä»¤å’Œè¦æ±‚")

        return suggestions[:5]  # æœ€å¤š5æ¡å»ºè®®
